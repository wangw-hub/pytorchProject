# -*- coding: utf-8 -*-
"""
@File    : ResNet50.py
@Time    : 2026/2/10 11:51 Tuesday
@Author  : wangw
@Email   : wangw_heart@163.com
@Description: 
"""
# ==========================================
# ğŸ›‘ å¿…é¡»æ”¾åœ¨æœ€å‰é¢ï¼Œé˜²æ­¢ PyCharm è¿œç¨‹ç»˜å›¾å¡æ­»
import matplotlib

matplotlib.use('Agg')
# ==========================================

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import time
import os

# ================= âš™ï¸ é«˜è´Ÿè½½é…ç½®åŒº =================
# æ˜¾å­˜å‹åŠ›æµ‹è¯•ï¼šå¦‚æœæ˜¾å­˜æŠ¥é”™ï¼Œè¯·å°† BATCH_SIZE è°ƒå° (ä¾‹å¦‚ 64)
BATCH_SIZE = 128
# è®¡ç®—å‹åŠ›æµ‹è¯•ï¼šResNet50 + 64x64åˆ†è¾¨ç‡
EPOCHS = 20
LEARNING_RATE = 0.01
# WSL2 å»ºè®®è®¾ä¸º 2 æˆ– 4ï¼Œè®¾å¤ªå¤§å¯èƒ½ä¼šå¯¼è‡´ CPU å†…å­˜äº¤æ¢å¡é¡¿
NUM_WORKERS = 4


# ===================================================

def get_device_info():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ è®¡ç®—è®¾å¤‡: {device}")
    if device.type == 'cuda':
        props = torch.cuda.get_device_properties(0)
        print(f"   æ˜¾å¡å‹å·: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜æ€»é‡: {props.total_memory / 1024 ** 3:.2f} GB")
        print(f"   å¤šå¤„ç†å™¨(SM)æ•°é‡: {props.multi_processor_count}")
    return device


device = get_device_info()

# 1. æ•°æ®å‡†å¤‡ (é«˜è´Ÿè½½ç‰ˆ)
print("\nğŸ“¦ æ­£åœ¨åŠ è½½å¹¶é¢„å¤„ç†æ•°æ® (Resize -> 64x64)...")

# å¼ºè¡Œæ”¾å¤§å›¾ç‰‡ï¼Œå¢åŠ  GPU ååå‹åŠ›
transform_train = transforms.Compose([
    transforms.Resize(64),  # <--- å…³é”®ç‚¹ï¼šåˆ†è¾¨ç‡ç¿»å€ï¼Œè®¡ç®—é‡ x4
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

# 2. å®šä¹‰é‡å‹æ¨¡å‹ (ResNet50)
print("ğŸ—ï¸ æ­£åœ¨åŠ è½½ ResNet50 æ¨¡å‹ (å‚æ•°é‡å·¨å¤§)...")
# ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå¼ºè¿«æ˜¾å¡ä»é›¶è®¡ç®—æ¢¯åº¦
model = torchvision.models.resnet50(weights=None, num_classes=10)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)
scaler = torch.amp.GradScaler('cuda')  # æ··åˆç²¾åº¦

# 3. è®­ç»ƒå¾ªç¯
print(f"\nğŸ”¥ å¼€å§‹é«˜è´Ÿè½½è®­ç»ƒ (å…± {EPOCHS} è½®)...")
print(f"   é¢„è®¡è€—æ—¶: 8 ~ 12 åˆ†é’Ÿ")
print("-" * 60)

train_losses = []
train_accs = []
start_time = time.time()

for epoch in range(EPOCHS):
    epoch_start = time.time()
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    # è¿›åº¦æ¡
    pbar = tqdm(trainloader, desc=f'Epoch {epoch + 1}/{EPOCHS}', leave=False)

    for inputs, labels in pbar:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with torch.amp.autocast('cuda'):
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        # ç»Ÿè®¡æ•°æ®
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        # å®æ—¶æ›´æ–°è¿›åº¦æ¡åç¼€
        pbar.set_postfix({'Loss': f"{running_loss / (pbar.n + 1):.4f}", 'Acc': f"{100. * correct / total:.2f}%"})

    # Epoch ç»“æŸç»Ÿè®¡
    epoch_duration = time.time() - epoch_start
    epoch_loss = running_loss / len(trainloader)
    epoch_acc = 100. * correct / total
    train_losses.append(epoch_loss)
    train_accs.append(epoch_acc)

    # æ‰“å°è¯¥è½®ç®€æŠ¥ï¼ˆé¿å…æ¯ä¸€æ­¥éƒ½æ‰“å°å¯¼è‡´å¡é¡¿ï¼‰
    tqdm.write(f"âœ… Epoch {epoch + 1} | Time: {epoch_duration:.1f}s | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%")

total_time = time.time() - start_time
print("-" * 60)
print(f"ğŸ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time / 60:.2f} åˆ†é’Ÿ")

# 4. ä¿å­˜å¹¶ç»˜åˆ¶ç»“æœ
print("ğŸ“Š æ­£åœ¨ç”Ÿæˆç»“æœå›¾è¡¨...")
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss', color='red')
plt.title('Loss Curve (ResNet50)')
plt.xlabel('Epoch')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(train_accs, label='Training Accuracy', color='blue')
plt.title('Accuracy Curve (ResNet50)')
plt.xlabel('Epoch')
plt.grid(True)

save_path = './training_result.png'
plt.savefig(save_path)
print(f"ğŸ‰ å›¾è¡¨å·²ä¿å­˜ä¸º: {os.path.abspath(save_path)}")
plt.close()  # å…³é—­ç”»å¸ƒï¼Œé‡Šæ”¾å†…å­˜