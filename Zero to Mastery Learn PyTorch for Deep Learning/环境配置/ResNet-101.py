# -*- coding: utf-8 -*-
"""
@File    : ResNet-101.py
@Time    : 2026/2/11 ä¸‹åˆ4:36 æ˜ŸæœŸä¸‰
@Author  : wangw
@Email   : wangw_heart@163.com
@Description: 
"""
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import os
import time
from tqdm import tqdm
import sys
# è§£å†³ä½ ä¹‹å‰çš„ OMP Error #15 å†²çª
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

def main():
    # ================= âš™ï¸ ç‹‚æš´æ¨¡å¼é…ç½®åŒº =================
    # é’ˆå¯¹ 8GB æ˜¾å­˜ï¼Œ128 batch + 224åˆ†è¾¨ç‡é€šå¸¸èƒ½å‹æ¦¨ 90% ä»¥ä¸Šæ˜¾å­˜
    BATCH_SIZE = 64
    EPOCHS = 5  # æ ¹æ®é€Ÿåº¦å¯è°ƒï¼ŒResNet101 è¾ƒæ…¢ï¼Œ5è½®é€šå¸¸è¶³å¤Ÿ 10 åˆ†é’Ÿ
    NUM_WORKERS = 8 # å……åˆ†åˆ©ç”¨ä½ è›Ÿé¾™ 16 Pro çš„å¤šæ ¸ CPU

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”¥ æ­£åœ¨å¯åŠ¨æ˜¾å¡: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ“¦ ç¯å¢ƒæ£€æŸ¥: PyTorch {torch.__version__} | CUDA {torch.version.cuda}")

    # 1. æ•°æ®å¢å¼ºï¼ˆå¢åŠ  CPU/GPU äº¤äº’è´Ÿæ‹…ï¼ŒæŠ¹å¹³æ³¢åŠ¨ï¼‰
    transform = transforms.Compose([
        transforms.Resize(224), # å¢åŠ åˆ° ImageNet æ ‡å‡†å°ºå¯¸ï¼Œè®¡ç®—é‡å‰§å¢
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.491, 0.482, 0.446), (0.202, 0.199, 0.201)),
    ])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)

    # å…³é”®ï¼šå¼€å¯ persistent_workers å’Œ pin_memory è§£å†³é˜¶æ®µæ€§åœé¡¿
    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,
                             num_workers=NUM_WORKERS, pin_memory=True,
                             persistent_workers=True)

    # 2. ä½¿ç”¨æ›´æ·±å±‚çš„ ResNet-101ï¼ˆè®¡ç®—å¯†åº¦è¿œè¶… ResNet50ï¼‰
    model = torchvision.models.resnet101(weights=None, num_classes=10).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
    # å¼€å¯æ··åˆç²¾åº¦è®­ç»ƒï¼Œå……åˆ†å‘æŒ¥ RTX 5060 çš„ Tensor Core æ€§èƒ½
    scaler = torch.amp.GradScaler('cuda')

    print("\n[INFO] å‹åŠ›æµ‹è¯•å¼€å§‹ï¼Œè¯·è§‚å¯Ÿä»»åŠ¡ç®¡ç†å™¨ GPU åˆ©ç”¨ç‡...")
    print("-" * 50)

    model.train()
    start_time = time.time()

    for epoch in range(EPOCHS):
        e_start = time.time()
        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()

            with torch.amp.autocast('cuda'):
                outputs = model(inputs)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            if i % 20 == 0:
                # æ‰“å°æ˜¾å­˜å ç”¨ï¼Œç›‘æ§æ˜¯å¦è¾¾åˆ°æ»¡è½½
                mem = torch.cuda.memory_reserved(0) / 1024**3
                print(f"Epoch [{epoch+1}/{EPOCHS}] | Step [{i}/{len(trainloader)}] | æ˜¾å­˜å ç”¨: {mem:.2f}GB", end='\r',flush=True)

        print(f"\nâœ… Epoch {epoch+1} å®Œæˆï¼Œè€—æ—¶: {time.time() - e_start:.1f}s",flush=True)

    total_time = time.time() - start_time
    print("-" * 50)
    print(f"ğŸ æµ‹è¯•ç»“æŸï¼æ€»è€—æ—¶: {total_time/60:.2f} åˆ†é’Ÿ",flush=True)

if __name__ == '__main__':
    # Windows ä¸‹å¤šè¿›ç¨‹å¿…é¡»åŠ è¿™ä¸ª
    torch.multiprocessing.freeze_support()
    main()